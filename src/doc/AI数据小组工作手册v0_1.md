# AI数据标注工作手册 v0_1

![封面](images/fengmian.jpg)

[TOC]

## 0 前言

在科技迅猛发展的今天，计算机技术已经应用到了每个行业的方方面面。我们的生活也因这些技术而便利许多。其中，AI（Artificial Intelligence 人工智能）技术在近几年更是发展火热。例如：智能音箱的语音识别、电商平台的偏好推荐、手机美颜与场景识别优化等（参考[此文](https://zhuanlan.zhihu.com/p/42661568))。

我们目前主要开发的是计算机视觉方面的应用。顾名思义，通过神经网络训练使计算机具有识别某些图像的能力的模型。一般采用的是监督式学习的训练方法。例如，我们需要让计算机能够识别苹果这种水果，就需要准备大量且多样的苹果图片，图片标注出了苹果的位置范围，与大量不是苹果的图片喂给计算机学习。计算机通过算法，能够逐渐将苹果识别出来，并且不会将其它物体识别为苹果。当然具体的需求与流程会比这个复杂得多。

### 0.1 标注数据的几大类型

#### 0.1.1 bounding box（边界框）

一般在有分类识别需求的时候，需要用到此类标注数据，如手势识别、物体识别等。举个例子，某次需求中需要识别苹果、香蕉和梨三种水果。我们需要在这三种水果大量的图片中用边界框标注出目标物体的位置范围（如下图所示）。

![图1 边界框标注示例](images/%E5%9B%BE1%20%E8%BE%B9%E7%95%8C%E6%A1%86%E6%A0%87%E6%B3%A8%E7%A4%BA%E4%BE%8B.png)

应用实例：

- 短视频拍摄时根据用户比出的不同手势，给出对应的视频特效，或者根据手势控制视频录制的开始与暂停。
- 金鸡奖扫鸡活动，用户在生活场景里找寻与鸡有关的物体进行扫描，app识别出相关物体给出奖励。这个与支付宝每天的扫福活动相似，但是扫福活动只需要识别福字这一个类别，而扫鸡需要识别的类别很多，如动物鸡、玩偶鸡、玩具鸡、鸡腿、鸡翅、鸡块、炸鸡、鸡字...因此扫鸡活动的难度会比扫福活动高出许多。

边界框需要注意以下两点：

- 边界框的四条边要尽量贴合物体的边缘轮廓，不要有空隙。
- 由于边界框内部的图像信息将被算法工程师拿去当做模型训练的正样本信息，而边界框外部图像将默认当做训练的负样本信息，所以一张图片里的目标物体必须标全，不能有遗漏。

#### 0.1.2 关键点

目前用到这类标注数据的有人脸五官关键点、手势关键点、人体轮廓关键点、人体骨骼关键点等识别需求（如下图所示）。

![图2](images/%E5%9B%BE2.png)

应用实例：

- 利用人脸五官关键点的识别能力，可以实现美妆美颜、脸型微调、特效贴纸等功能。
- 利用人体骨骼关键点的识别能力，可以实现舞姿识别、玩偶模仿动作等特效功能。
- 利用人体轮廓关键点的识别能力，可以实现人体瘦身、长腿特效等功能。

关键点标注时要注意以下两点：

- 关键点一般标注在目标物体的**边缘轮廓**位置，标注时需要将图片放大到合适位置，看清楚图像边缘的像素边界。
- 关键点主要分为**指定点**和**均匀点**两类。指定点会有文档给出定义，标注时要严格遵循定义找到指定点。再以指定点为**锚点**，沿着目标物体的边缘轮廓定义出固定数量的均匀点，均匀点的第一原则是要点与点之间的距离是**均匀相等**的。

#### 0.1.3 语义分割

语义分割的标注方法，目前主要应用在头发分割、皮肤分割、人体分割等方面。（如下图所示）

![图3](images/%E5%9B%BE3.jpg)

应用实例：

- 利用头发分割能力，准确识别出用户的头发范围，从而实现更改发色等特效。
- 利用皮肤分割能力，准确识别出用户的脸部和脖子的皮肤范围，从而实现皮肤美白的特效。
- 利用人体分割能力，准确识别出用的身体轮廓，从而能够将人体从背景中分离出来，更换其他背景生成新的图片。

语义分割标注注意事项：

- 此项标注任务主要是将图片中需要分割的物体准确分离出来，所以标注时需要尽可能放大图片，看清楚轮廓。
- 


### 0.2 标注数据生产所需的基本能力

由上面的例子中，我们知道供给计算机做学习的数据集生产，是整个AI产品开发的前期工作。此项工作的质量好坏直接影响到产品的质量。因此，在商业公司的AI部门，数据标注人员应该具备以下基本能力。

- **严谨的工作态度**，在数据生产的每一个环节，都应该要保持严谨的工作态度。因为如果在任何一个环节出现了差错，都有可能导致公司整个项目出现问题而造成损失。并且小失误的影响会被放大。
- **对需求的理解能力**，在生产中的每一个环节中的同事，都要充分理解算法工程师提出的需求里的每一个细节点。严格按照要求来去工作。因为“努力不一定有用，如果方向一开始是错”。
- **发现问题的能力**，无论是数据生产负责人，还是数据标注员，都要在**对接需求**时及时发现需求文档中未提及的问题，因为算法工程师提需求时，不一定会考虑到所有情况，这时数据生产对接人和标注员都要具备基本的职业素养，能够根据积累的经验，及时提出可能出现的问题与算法工程师确认。在**实际工作中**，有遇到的需求文档里未提及的情况也要及时和算法工程师提出。整个过程中，所解决的问题要及时补充进工作文档中，并且确保所有相关人员都已经同步到了最新的工作标准。
- **与工作相关人员的沟通能力**，在工作过程中，沟通能力非常重要。遇到问题要第一时间与负责人沟通。凡是因为问题没有及时沟通，而已经产生了不好的影响，都不能以问题为借口，发现问题的人负有主要责任。
- **文件归档与整理能力**，数据标注工作中会涉及到大量的文件，因此工作人员应该具备基本的文件归档与整理能力。文件的整理与命名，要严格按照文档要求。文件在传输过程中，尽量使用复制方法。只有在数据存档与备份妥当后，方可删掉工作文件。


## 1 数据标注流程

### 1.1 流程图

![流程图](images/%E6%B5%81%E7%A8%8B%E5%9B%BE.png)

### 1.2 流程图说明

标注数据生产过程整体分为两个阶段：**需求对接**与**数据生产**。当然这两个阶段的工作并不是
相互独立的，有时会根据实际情况交替进行。

#### 1.2.1 **需求对接**

流程图的第一部分就是需求对接流程的主要细节。当算法工程师提出数据需求后，数据组长会与其对接需求的细节。需要确认以下几点细节：

- 首先要确定的是此次需求要生产的是什么[**数据类型**](#01-标注数据的几大类型)。
- 然后要确定的是此批数据需求的**使用目的**是什么，数据生产各个环节的所有人员都应该要知道生产出来的数据使用目的是什么，从使用目的或者使用场景出发，去考虑问题，会更加周全，也更利于生产过程中发现之前没考虑到的问题。
- 接着要确定的是这批数据所需要的**数量**是多少、**截止时间**是什么时候，数据组长会根据数量和截止时间，依据以往经验预计工作能否按时完成。
- 最后，要确认的是需求的**具体内容**，比如需要怎么样的特殊场景、图片拍摄的需要怎么样的角度等等。

以上确定的内容，需要以图片与文字说明的形式编辑成一个文档，留作备案。

在对需求做了初步分析之后，还需要考虑原始数据的来源问题，主要包括四个来源：

- 公开数据集，可以通过搜索引擎搜索，看看网上是否已经有了符合我们需求的公开数据集。如果能找到符合要求或者基本符合要求的数据集，会大大节约我们工作成本。当然公开数据集不一定能够完全符合我们的要求，有些还需要通过[数据清洗]()、[数据格式转换]()等处理步骤后，数据集才能正常使用。这里也要注意公开数据集的使用条款，尊重数据集所有者的劳动成果。
- 网络爬虫，有些需求的数据可以直接在网络中获取。编写爬虫脚本进行数据爬取也能够大幅节约工作成本。但也要注意脚本的编写规范，不能编写恶意爬虫，有版权保护的数据切勿爬取。
- 已有数据集，有些数据需求其实是可以使用已有的数据集，进行二次生产。所以面对新的需求时，要考虑好是否有已有的数据集满足或部分满足新需求，从而避免不必要的重复工作。
- 数据采集，当以上三个来源都不能满足新需求时，就需要计划安排[数据采集]()工作。采集工作开始前，需要进行采集试验，试验要完全满足需求文档里所提到的每一个细节点。试验方案可行后，方可编写采集文档。在文档中要体现采集示例、采集方法、步骤、成员、总量与分配到个人的数量、注意事项和截止时间等信息。

数据生产过程中会需要应用到满足特别需求的工具，好用的工具能使工作事半功倍。主要用到了**数据采集、数据清洗、数据处理和数据标注四大类工具**。

数据采集工具目前主要是由安卓同事开发的[HumanAction]()，此工具目前支持图片连续帧和间隔帧采集，采集后可自动标注出人脸280关键点、手势分类、人体骨骼关键点等信息。

数据清洗工具目前主要用的是由标注团队自主开发的[imageView]()，此工具目前支持批量清洗图片，将图片分为正确和错误两类后对方到对应文件夹，并且生成对应文件列表的TXT。

数据处理工具目前主要用的是由标注团队自主开发的[AI dataset processing tool]()，此工具目前支持视频截帧、文件批量重命名、图片文件重写、图片间隔选取、TXT信息整合、图片任务分配、文件名批量写入TXT等功能。工具主要针对生产过程中的文件处理需求所开发，功能会持续补充。

数据标注工具目前主要用的是opencv团队开发的[CVAT](https://github.com/opencv/cvat/)工具，此工具适合团队多人在线标注，开发社区活跃，功能还在持续增加中，适合长期更新使用。针对工具的一些不足，标注团队也在优化工具与编写功能脚本，使工作流程更加高效，如任务批量部署、任务批量分配等功能。还有一款开源工具叫[labelimg](https://github.com/tzutalin/labelImg)，此工具适合单人单机标注，生成VOC格式标注数据，但是多人共同工作时此工具**慎用**！因为数据分散与收集的多余步骤，会增加出错的风险。

ps:在团队协作中，会有体积稍微大些的文件需要传输，微信并不适用。目前统一使用[钉钉](https://page.dingtalk.com/wow/dingtalk/act/download?spm=a213l2.13146415.7065056597.9.7f1518e6Lwtxq4)来作为工作沟通、文件传输工具。

#### 1.2.2 **数据生产**

数据需求对接好后，就开始数据生产工作，工作主要包括以下两种种类型：

#### 1.2.2.1 数据采集

**采集方案文档编辑**：在充分理解数据需求文档之后，即开始数据采集工作。采集工作开始前，需要进行采集试验，试验要完全满足需求文档里所提到的每一个细节点。试验方案可行后，方可编写采集方案文档。在文档中要体现采集示例、采集方法、步骤、成员、总量与分配到个人的数量、注意事项和截止时间等信息。

**数据采集**：数据采集同事根据采集方案文档，严格执行步骤。如果在过程中遇到问题，要及与采集负责人提出，问题解决后要及时将修正的方案同步给所有采集人员。

**数据整理与提交**：数据采集完毕后，不可直接将数据提交给负责人。还应该用数据处理工具（[AI dataset processing tool]()），按照要求进行重命名、修改大小、修改方向等操作。确认没有问题后方可提交。

**背景数据采集**：

#### 1.2.2.2 数据标注/清洗

对于采集好的图片数据，有两种标注方法：

- **自动标注**：使用已有模型，对采集好的数据进行预测，再将预标注好的数据进行修改或者人工数据清洗。

（数据清洗流程与数据标注流程近乎相同，故以下只说明数据标注工作流程）

- **人工标注**：当没有稍微准确可靠的模型时，则进行人工标注工作。

人工标注有以下几个步骤：

**数据试标注**：数据采集负责人组织两三个同事，按照数据需求进行试标注。试标注时需要尽量找出所有需求文档里没有描述清楚的问题，与算法同事敲定清楚。并且得出标注效率，一般以每三个小时标注平均量留作工作任务量安排参考。

**编写标注规则文档**：根据需求文档的要求和数据试标注时发现的问题的答案，编写标注规则文档。文档还要包含标注效率信息。此文档留作标注员培训使用，也用作标注审核的参考文档。文档后续也会持续更新新增问题，每次修改，都要同步到所有标注人员。

**标注员标注测试**：将数据试标注的数据任务，重新布置给标注员作业。标注人员要充分阅读理解标注文档后开始测试。通过计算标注员与试标注数据之间的差异，判断该成员是否理解标注规则，满足者即可开始标注工作。不满足要求的人员需要重新阅读规则文档，直到满足为止。

**标注工作**：标注员按照规则文档，在指定的时间完成指定数量准确的标注任务。标注过程中遇到的问题要及时提出，解决后负责人及时将最新要求同步给所有标注同事。

**标注结果审核**：对标注好的数据进行审核，是整个工作流程的重要环节。审核的标准把控，直接影响了工作成果的好与坏。目前审核工作会涵盖以下两种方法：

- **程序审核**：在每次任务布置的时候，程序会随机安插占总量一定百分比的已知标准数据进入新任务中，当此任务完后后，程序能够自动计算标注员标注与标准结果之间的差距值，由此判断此任务的可靠程度。分数较低的任务需要标注员重新阅读标注规则，自行修改标注任务，修改的时间不计入工作时间。如果标注人员差距值一直偏高，将影响绩效考核。

- **人工审核**：通常有全量审核和抽样审核两种形式。全量审核指将所有工作成果人工审核一遍，一般要保证数据完全正确。抽样审核会将工作成果按照一定比例抽出进行审核，也需要较高的通过率，因为是人工作业，所以不允许出现特别大的错误，正确率至少不能低于98%。

但是这里要强调一点：**审核工作虽然是整个流程中质量把控的重要环节，但并不是质量把控的主要控制因素**。当工作成果审核不通过的时候，能做的就只有亡羊补牢。亡羊补牢有的时候来得及，可有的时候也是来不及的。这会大大影响整个业务的研发进度，从而造成损失。所以控制成果质量的主要因素来自审核前的数据负责人和标注人，只有通过符合规范的生成流程、严谨的工作态度，将错误扼杀在发生之前，才能有效的提交高质量的数据并且不失效率。对于多次出现问题的同事，将影响到绩效考核，如果多次出现问题，则说明不适合此类型工作。


## 2 数据需求对接人工作规范



### 采集方案文档

## 3 数据采集与标注规范

## 4 数据处理规范

### 4.1 脚本规范

### 4.2 常用文件处理方法

#### 4.2.1 大量文件按照指定数目分配

```python
import os
import shutil

def files_distribution(target_path, per_task_count, tasks_path, task_dir_prename):
    '''
    target_path:需要移动文件的目标文件夹路径
    per_task_count:每个任务需要的数量
    tasks_path:存放任务文件夹的路径
    task_dir_prename:任务文件夹命名前缀
    RETURN:NONE
    '''
    task_num = 0
    for idx, file in enumerate(os.listdir(target_path)):
        if idx % per_task_count == 0:
            task_dir_path = os.path.join(tasks_path, '%s_%04d'%(task_dir_prename, task_num))
            if not os.path.exists(task_dir_path):
                os.mkdir(task_dir_path)
            task_num += 1
        file_path = os.path.join(target_path, file)
        to_file_path = os.path.join(task_dir_path, file)
        shutil.copy(file_path, to_file_path)
```

### 4.2 爬虫

### 4.3 常用Linux命令

#### 4.3.1 查看当前路径下每个文件夹的个数

```bash
find . -maxdepth 1 -type d | while read dir; do count=$(find "$dir" -type f | wc -l); echo "$dir : $count"; done
```

#### 4.3.2 查找某种类型文件，统一执行某一操作

如下例子，递归查找/target/path/下的所有jpg文件，全部移动到/some/path/路径下：

```bash
find /target/path/ -name '*.jpg' -exec mv {} /some/path/ \;
```

## 5 绩效考核

信任

## 6.工具使用文档

### 6.1 CVAT使用文档
